{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T09:42:26.258649Z",
     "start_time": "2025-01-02T09:42:26.248106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pm4py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n"
   ],
   "id": "cb4e0367d1737400",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T13:29:38.673969Z",
     "start_time": "2025-01-02T13:29:37.920946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    event_log = pm4py.convert_to_dataframe(log)\n",
    "\n",
    "    return event_log\n",
    "\n",
    "event_log = import_xes(\"/Users/6706363/Downloads/BPI_Challenge_2013_closed_problems.xes\")"
   ],
   "id": "cee431fd16a533d4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1487/1487 [00:00<00:00, 3178.42it/s]\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T13:29:40.434522Z",
     "start_time": "2025-01-02T13:29:40.422928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "\n",
    "# Sort by 'time:timestamp' and 'case:concept:name'\n",
    "df = df.sort_values(by=['case:concept:name', 'time:timestamp'])\n",
    "\n",
    "df.head(n=10)"
   ],
   "id": "22602203fc21c62d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  case:concept:name concept:name org:resource            time:timestamp\n",
       "0       1-109135791       Queued       Minnie 2006-01-11 15:49:42+00:00\n",
       "1       1-109135791     Accepted       Minnie 2012-03-15 11:53:52+00:00\n",
       "2       1-109135791     Accepted       Minnie 2012-03-15 11:56:17+00:00\n",
       "3       1-109135791     Accepted       Minnie 2012-03-15 12:09:05+00:00\n",
       "4       1-109135791    Completed       Minnie 2012-03-15 12:11:33+00:00\n",
       "5       1-147898401     Accepted        Tomas 2006-11-07 10:00:36+00:00\n",
       "6       1-147898401     Accepted        Tomas 2006-11-07 13:05:44+00:00\n",
       "7       1-147898401     Accepted        Tomas 2009-12-02 14:24:32+00:00\n",
       "8       1-147898401     Accepted        Tomas 2011-09-03 07:09:09+00:00\n",
       "9       1-147898401     Accepted       Carrie 2012-01-20 10:23:24+00:00"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>time:timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-109135791</td>\n",
       "      <td>Queued</td>\n",
       "      <td>Minnie</td>\n",
       "      <td>2006-01-11 15:49:42+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-109135791</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>Minnie</td>\n",
       "      <td>2012-03-15 11:53:52+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-109135791</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>Minnie</td>\n",
       "      <td>2012-03-15 11:56:17+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-109135791</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>Minnie</td>\n",
       "      <td>2012-03-15 12:09:05+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-109135791</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Minnie</td>\n",
       "      <td>2012-03-15 12:11:33+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1-147898401</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>2006-11-07 10:00:36+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1-147898401</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>2006-11-07 13:05:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1-147898401</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>2009-12-02 14:24:32+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1-147898401</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>2011-09-03 07:09:09+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1-147898401</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>Carrie</td>\n",
       "      <td>2012-01-20 10:23:24+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:06:12.380427Z",
     "start_time": "2025-01-02T14:06:12.246687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_activity_resource_sequence(df, prefix_length):\n",
    "    sequences = []\n",
    "    grouped = df.groupby('case:concept:name')\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        activities = group['concept:name'].tolist()\n",
    "        resources = group['org:resource'].tolist()\n",
    "        \n",
    "        # Only include sequences with length >= prefix_length\n",
    "        if len(activities) < prefix_length:\n",
    "            # Remove the sequence (skip appending it to the list)\n",
    "            continue\n",
    "        \n",
    "        # Truncate to the desired prefix length\n",
    "        current_activities = activities[:prefix_length]\n",
    "        current_resources = resources[:prefix_length]  # Include all resources\n",
    "        \n",
    "        # Combine activities and resources into tuples (no changes for the last activity)\n",
    "        sequence = []\n",
    "        for i in range(len(current_activities)):\n",
    "            # For all activities, include both activity and resource\n",
    "            sequence.append((current_activities[i], current_resources[i]))\n",
    "        \n",
    "        # Add the valid sequence to the list\n",
    "        sequences.append(sequence)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "sequences = create_activity_resource_sequence(df,30)\n",
    "\n",
    "# Initialize a set to store unique 'R' values\n",
    "unique_R = set()\n",
    "\n",
    "# Loop through the list of sequences and extract the 'R' values\n",
    "for sequence in sequences:\n",
    "    for item in sequence:\n",
    "        # item[1] is the second element (the part with 'R')\n",
    "        unique_R.add(item[1])\n",
    "\n",
    "# The length of the set will give the number of unique occurrences of 'R'\n",
    "print(len(unique_R))"
   ],
   "id": "5882787dea495278",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:06:14.891595Z",
     "start_time": "2025-01-02T14:06:14.871278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the list of activities and resources\n",
    "activities = []\n",
    "resources = []\n",
    "\n",
    "# Loop through sequences to gather activities and resources\n",
    "for seq in sequences:\n",
    "    for i, item in enumerate(seq):\n",
    "        activity, resource = item  # Each item is (activity, resource)\n",
    "        # Replace NaN resource with 'none'\n",
    "        if pd.isna(resource):  # Check if the resource is NaN\n",
    "            resource = 'none'\n",
    "        activities.append(activity)\n",
    "        resources.append(resource)\n",
    "\n",
    "# Fit the OneHotEncoder to the unique activities and resources\n",
    "activity_encoder = OneHotEncoder() \n",
    "resource_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit the encoder on unique activities and resources\n",
    "activity_encoder.fit([[activity] for activity in set(activities)])\n",
    "resource_encoder.fit([[resource] for resource in set(resources)])\n",
    "\n",
    "# Encode activities and resources\n",
    "encoded_sequences = []\n",
    "y_encoded = []  # List to store the one-hot encoded target resource for the last activity\n",
    "\n",
    "for seq in sequences:\n",
    "    activity_onehots = []\n",
    "    \n",
    "    # For each activity-resource pair, apply one-hot encoding\n",
    "    for i, item in enumerate(seq):\n",
    "        activity, resource = item\n",
    "        # Replace NaN resource with 'none' during encoding\n",
    "        if pd.isna(resource):  # Check if the resource is NaN\n",
    "            resource = 'none'\n",
    "        activity_onehot = activity_encoder.transform([[activity]]).toarray()\n",
    "        \n",
    "        # If it's the last item, we only encode the activity and store the resource for y\n",
    "        if i == len(seq) - 1:\n",
    "            # Add only the activity one-hot encoding\n",
    "            activity_onehots.append(activity_onehot)\n",
    "            # One-hot encode the resource and store it for prediction (y)\n",
    "            resource_onehot = resource_encoder.transform([[resource]]).toarray()\n",
    "            y_encoded.append(resource_onehot)  # Store the one-hot encoded resource\n",
    "        else:\n",
    "            # For all other activities, include both activity and resource one-hot encoding\n",
    "            resource_onehot = resource_encoder.transform([[resource]]).toarray()\n",
    "            encoded_sequence = np.hstack([activity_onehot, resource_onehot])\n",
    "            activity_onehots.append(encoded_sequence)\n",
    "    \n",
    "    # If there is more than one activity in the sequence, add the zero vector for the last resource\n",
    "    if len(seq) > 1:\n",
    "        last_activity_onehot = activity_onehots[-1]\n",
    "        last_resource_onehot = np.zeros(resource_onehot.shape)  # Zero vector for the last resource\n",
    "        activity_onehots[-1] = np.hstack([last_activity_onehot, last_resource_onehot])\n",
    "    \n",
    "    # Concatenate the encoded activities and resources for the full sequence\n",
    "    encoded_sequences.append(np.vstack(activity_onehots))\n",
    "\n",
    "X = np.array(encoded_sequences)\n",
    "y = np.array(y_encoded)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ],
   "id": "63c5cbbe1bc242c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30, 9)\n",
      "(1, 1, 7)\n"
     ]
    }
   ],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:06:18.316203Z",
     "start_time": "2025-01-02T14:06:18.312991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_labels = label_encoder.fit_transform([np.argmax(y_i) for y_i in y])\n"
   ],
   "id": "b580d20cb020be27",
   "outputs": [],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T14:06:27.917394Z",
     "start_time": "2025-01-02T14:06:27.856634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flatten the sequences as you did before\n",
    "X_flattened = np.array([seq.sum(axis=0) for seq in X])\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring={'f1_weighted': make_scorer(f1_score, average='weighted')},  # F1 weighted as scoring metric\n",
    "    refit='f1_weighted',  # Refit using the best scoring parameter combination\n",
    "    cv=kf,  # Cross-validation strategy\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_flattened, y_labels)\n",
    "\n",
    "# Print the best parameters and corresponding score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1-Weighted Score:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best classifier for evaluation\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Perform cross-validation with the best estimator\n",
    "cv_results = cross_validate(\n",
    "    best_clf, X_flattened, y_labels,\n",
    "    cv=kf,\n",
    "    scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'],\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# Print cross-validation metrics with four decimal places\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(\"Accuracy (mean ± std): {:.4f} ± {:.4f}\".format(np.mean(cv_results['test_accuracy']), np.std(cv_results['test_accuracy'])))\n",
    "print(\"Precision (mean ± std): {:.4f} ± {:.4f}\".format(np.mean(cv_results['test_precision_weighted']), np.std(cv_results['test_precision_weighted'])))\n",
    "print(\"Recall (mean ± std): {:.4f} ± {:.4f}\".format(np.mean(cv_results['test_recall_weighted']), np.std(cv_results['test_recall_weighted'])))\n",
    "print(\"F1 (mean ± std): {:.4f} ± {:.4f}\".format(np.mean(cv_results['test_f1_weighted']), np.std(cv_results['test_f1_weighted'])))\n"
   ],
   "id": "dfd6247a43d9ee2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 432 candidates, totalling 864 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=2 greater than the number of samples: n_samples=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[188], line 31\u001B[0m\n\u001B[1;32m     20\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(\n\u001B[1;32m     21\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mclf,\n\u001B[1;32m     22\u001B[0m     param_grid\u001B[38;5;241m=\u001B[39mparam_grid,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     27\u001B[0m     n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     28\u001B[0m )\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Perform the grid search\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_flattened\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Print the best parameters and corresponding score\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest Parameters:\u001B[39m\u001B[38;5;124m\"\u001B[39m, grid_search\u001B[38;5;241m.\u001B[39mbest_params_)\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1019\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m   1013\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m   1014\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m   1015\u001B[0m     )\n\u001B[1;32m   1017\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m-> 1019\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1021\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m   1022\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m   1023\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1573\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1571\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1572\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1573\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:977\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    957\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    958\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    959\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    960\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    961\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    962\u001B[0m         )\n\u001B[1;32m    963\u001B[0m     )\n\u001B[1;32m    965\u001B[0m out \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[1;32m    966\u001B[0m     delayed(_fit_and_score)(\n\u001B[1;32m    967\u001B[0m         clone(base_estimator),\n\u001B[1;32m    968\u001B[0m         X,\n\u001B[1;32m    969\u001B[0m         y,\n\u001B[1;32m    970\u001B[0m         train\u001B[38;5;241m=\u001B[39mtrain,\n\u001B[1;32m    971\u001B[0m         test\u001B[38;5;241m=\u001B[39mtest,\n\u001B[1;32m    972\u001B[0m         parameters\u001B[38;5;241m=\u001B[39mparameters,\n\u001B[1;32m    973\u001B[0m         split_progress\u001B[38;5;241m=\u001B[39m(split_idx, n_splits),\n\u001B[1;32m    974\u001B[0m         candidate_progress\u001B[38;5;241m=\u001B[39m(cand_idx, n_candidates),\n\u001B[1;32m    975\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_and_score_kwargs,\n\u001B[1;32m    976\u001B[0m     )\n\u001B[0;32m--> 977\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001B[38;5;129;01min\u001B[39;00m \u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    978\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    979\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    980\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    981\u001B[0m )\n\u001B[1;32m    983\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    984\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    985\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    986\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    987\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    988\u001B[0m     )\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_split.py:409\u001B[0m, in \u001B[0;36m_BaseKFold.split\u001B[0;34m(self, X, y, groups)\u001B[0m\n\u001B[1;32m    407\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m _num_samples(X)\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_splits \u001B[38;5;241m>\u001B[39m n_samples:\n\u001B[0;32m--> 409\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    410\u001B[0m         (\n\u001B[1;32m    411\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot have number of splits n_splits=\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m greater\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    412\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m than the number of samples: n_samples=\u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    413\u001B[0m         )\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_splits, n_samples)\n\u001B[1;32m    414\u001B[0m     )\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39msplit(X, y, groups):\n\u001B[1;32m    417\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m train, test\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot have number of splits n_splits=2 greater than the number of samples: n_samples=1."
     ]
    }
   ],
   "execution_count": 188
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
