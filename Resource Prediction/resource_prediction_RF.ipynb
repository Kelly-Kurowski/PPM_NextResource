{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-10T09:13:28.628659Z",
     "start_time": "2025-02-10T09:13:20.919267Z"
    }
   },
   "source": [
    "import pm4py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T09:14:36.961809Z",
     "start_time": "2025-02-10T09:13:32.516876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    event_log = pm4py.convert_to_dataframe(log)\n",
    "\n",
    "    return event_log\n",
    "\n",
    "event_log = import_xes(\"/Users/6706363/Downloads/BPI_Challenge_2019.xes\")"
   ],
   "id": "f8c31ad5c247289e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "parsing log, completed traces :: 100%|██████████| 251734/251734 [00:31<00:00, 7989.86it/s] \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T09:15:51.746383Z",
     "start_time": "2025-02-10T09:15:50.827487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "\n",
    "# Sort by 'time:timestamp' and 'case:concept:name'\n",
    "df = df.sort_values(by=['case:concept:name', 'time:timestamp'])\n",
    "\n",
    "# df = df.sort_values(by=['org:resource', 'time:timestamp'])\n",
    "\n",
    "df.head(n=10)"
   ],
   "id": "4e7298df9bb3f2c1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       case:concept:name               concept:name org:resource  \\\n",
       "118143  4507004931_00010     Vendor creates invoice         NONE   \n",
       "118144  4507004931_00010  Vendor creates debit memo         NONE   \n",
       "118153  4507004931_00020     Vendor creates invoice         NONE   \n",
       "118154  4507004931_00020  Vendor creates debit memo         NONE   \n",
       "118163  4507004931_00030     Vendor creates invoice         NONE   \n",
       "118164  4507004931_00030  Vendor creates debit memo         NONE   \n",
       "118173  4507004931_00040     Vendor creates invoice         NONE   \n",
       "118174  4507004931_00040  Vendor creates debit memo         NONE   \n",
       "118183  4507004931_00050     Vendor creates invoice         NONE   \n",
       "118184  4507004931_00050  Vendor creates debit memo         NONE   \n",
       "\n",
       "                  time:timestamp  \n",
       "118143 1948-01-26 22:59:00+00:00  \n",
       "118144 1948-01-26 22:59:00+00:00  \n",
       "118153 1948-01-26 22:59:00+00:00  \n",
       "118154 1948-01-26 22:59:00+00:00  \n",
       "118163 1948-01-26 22:59:00+00:00  \n",
       "118164 1948-01-26 22:59:00+00:00  \n",
       "118173 1948-01-26 22:59:00+00:00  \n",
       "118174 1948-01-26 22:59:00+00:00  \n",
       "118183 1948-01-26 22:59:00+00:00  \n",
       "118184 1948-01-26 22:59:00+00:00  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>time:timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118143</th>\n",
       "      <td>4507004931_00010</td>\n",
       "      <td>Vendor creates invoice</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1948-01-26 22:59:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118144</th>\n",
       "      <td>4507004931_00010</td>\n",
       "      <td>Vendor creates debit memo</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1948-01-26 22:59:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118153</th>\n",
       "      <td>4507004931_00020</td>\n",
       "      <td>Vendor creates invoice</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1948-01-26 22:59:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118154</th>\n",
       "      <td>4507004931_00020</td>\n",
       "      <td>Vendor creates debit memo</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1948-01-26 22:59:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118163</th>\n",
       "      <td>4507004931_00030</td>\n",
       "      <td>Vendor creates invoice</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1948-01-26 22:59:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118164</th>\n",
       "      <td>4507004931_00030</td>\n",
       "      <td>Vendor creates debit memo</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1948-01-26 22:59:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118173</th>\n",
       "      <td>4507004931_00040</td>\n",
       "      <td>Vendor creates invoice</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1948-01-26 22:59:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118174</th>\n",
       "      <td>4507004931_00040</td>\n",
       "      <td>Vendor creates debit memo</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1948-01-26 22:59:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118183</th>\n",
       "      <td>4507004931_00050</td>\n",
       "      <td>Vendor creates invoice</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1948-01-26 22:59:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118184</th>\n",
       "      <td>4507004931_00050</td>\n",
       "      <td>Vendor creates debit memo</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1948-01-26 22:59:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T13:46:55.847046Z",
     "start_time": "2025-01-24T13:46:44.479075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_activity_resource_sequence(df, prefix_length):\n",
    "    sequences = []\n",
    "    grouped = df.groupby('case:concept:name')\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        activities = group['concept:name'].tolist()\n",
    "        resources = group['org:resource'].tolist()\n",
    "        \n",
    "        # Only include sequences with length >= prefix_length\n",
    "        if len(activities) < prefix_length:\n",
    "            # Remove the sequence (skip appending it to the list)\n",
    "            continue\n",
    "        \n",
    "        # Truncate to the desired prefix length\n",
    "        current_activities = activities[:prefix_length]\n",
    "        current_resources = resources[:prefix_length]  # Include all resources\n",
    "        \n",
    "        # Combine activities and resources into tuples (no changes for the last activity)\n",
    "        sequence = []\n",
    "        for i in range(len(current_activities)):\n",
    "            # For all activities, include both activity and resource\n",
    "            sequence.append((current_activities[i], current_resources[i]))\n",
    "        \n",
    "        # Add the valid sequence to the list\n",
    "        sequences.append(sequence)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "sequences = create_activity_resource_sequence(df,35)"
   ],
   "id": "2e58083941bfeebf",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T13:47:25.393699Z",
     "start_time": "2025-01-24T13:46:55.851315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the list of activities and resources\n",
    "activities = []\n",
    "resources = []\n",
    "\n",
    "# Loop through sequences to gather activities and resources\n",
    "for seq in sequences:\n",
    "    for i, item in enumerate(seq):\n",
    "        activity, resource = item  # Each item is (activity, resource)\n",
    "        # Replace NaN resource with 'none'\n",
    "        if pd.isna(resource):  # Check if the resource is NaN\n",
    "            resource = 'none'\n",
    "        activities.append(activity)\n",
    "        resources.append(resource)\n",
    "\n",
    "# Fit the OneHotEncoder to the unique activities and resources\n",
    "activity_encoder = OneHotEncoder() \n",
    "resource_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit the encoder on unique activities and resources\n",
    "activity_encoder.fit([[activity] for activity in set(activities)])\n",
    "resource_encoder.fit([[resource] for resource in set(resources)])\n",
    "\n",
    "# Encode activities and resources\n",
    "encoded_sequences = []\n",
    "y_encoded = []  # List to store the one-hot encoded target resource for the last activity\n",
    "\n",
    "for seq in sequences:\n",
    "    activity_onehots = []\n",
    "    \n",
    "    # For each activity-resource pair, apply one-hot encoding\n",
    "    for i, item in enumerate(seq):\n",
    "        activity, resource = item\n",
    "        # Replace NaN resource with 'none' during encoding\n",
    "        if pd.isna(resource):  # Check if the resource is NaN\n",
    "            resource = 'none'\n",
    "        activity_onehot = activity_encoder.transform([[activity]]).toarray()\n",
    "        \n",
    "        # If it's the last item, we only encode the activity and store the resource for y\n",
    "        if i == len(seq) - 1:\n",
    "            # Add only the activity one-hot encoding\n",
    "            activity_onehots.append(activity_onehot)\n",
    "            # One-hot encode the resource and store it for prediction (y)\n",
    "            resource_onehot = resource_encoder.transform([[resource]]).toarray()\n",
    "            y_encoded.append(resource_onehot)  # Store the one-hot encoded resource\n",
    "        else:\n",
    "            # For all other activities, include both activity and resource one-hot encoding\n",
    "            resource_onehot = resource_encoder.transform([[resource]]).toarray()\n",
    "            encoded_sequence = np.hstack([activity_onehot, resource_onehot])\n",
    "            activity_onehots.append(encoded_sequence)\n",
    "    \n",
    "    # If there is more than one activity in the sequence, add the zero vector for the last resource\n",
    "    if len(seq) > 1:\n",
    "        last_activity_onehot = activity_onehots[-1]\n",
    "        last_resource_onehot = np.zeros(resource_onehot.shape)  # Zero vector for the last resource\n",
    "        activity_onehots[-1] = np.hstack([last_activity_onehot, last_resource_onehot])\n",
    "    \n",
    "    # Concatenate the encoded activities and resources for the full sequence\n",
    "    encoded_sequences.append(np.vstack(activity_onehots))\n",
    "\n",
    "X = np.array(encoded_sequences)\n",
    "y = np.array(y_encoded)"
   ],
   "id": "896fb063aae6a5c7",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T13:47:33.519847Z",
     "start_time": "2025-01-24T13:47:27.872400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_flattened = [sequence.flatten() for sequence in X]\n",
    "X_flattened = np.array(X_flattened)  # Convert to a NumPy array\n",
    "y_single_label = np.array([np.argmax(label) for label in y])\n",
    "\n",
    "# Parameter distribution for RandomizedSearchCV\n",
    "# param_dist = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'bootstrap': [True, False],\n",
    "# }\n",
    "\n",
    "# param_dist = {\n",
    "#     'n_estimators': [50, 100],  # Reduced values\n",
    "#     'max_depth': [10, 20],      # Narrowed search\n",
    "#     'min_samples_split': [2, 5],\n",
    "#     'min_samples_leaf': [1, 2],\n",
    "#     'bootstrap': [True]\n",
    "# }\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50],  # Reduce options further\n",
    "    'max_depth': [None],    # Single value\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [1],\n",
    "    'bootstrap': [False],\n",
    "}\n",
    "\n",
    "# Create the RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Use RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Number of iterations to sample from the parameter space\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search.fit(X_flattened, y_single_label)\n",
    "\n",
    "# Print the best parameters found by RandomizedSearchCV\n",
    "print(\"Best parameters found by RandomizedSearchCV:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Get the best RandomForest model\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# KFold cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists for performance metrics\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform KFold cross-validation\n",
    "for train_idx, test_idx in kf.split(X_flattened):\n",
    "    X_train, X_test = X_flattened[train_idx], X_flattened[test_idx]\n",
    "    y_train, y_test = y_single_label[train_idx], y_single_label[test_idx]\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    best_rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics for the fold\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    precisions.append(precision_score(y_test, y_pred, average='weighted', zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# Compute mean and standard deviation for each metric\n",
    "metrics = {\n",
    "    'Accuracy': (np.mean(accuracies), np.std(accuracies)),\n",
    "    'Precision': (np.mean(precisions), np.std(precisions)),\n",
    "    'Recall': (np.mean(recalls), np.std(recalls)),\n",
    "    'F1-Score': (np.mean(f1_scores), np.std(f1_scores)),\n",
    "}\n",
    "\n",
    "# Print the results in the desired format\n",
    "for metric, (mean, std) in metrics.items():\n",
    "    print(f\"{metric}: {mean:.4f} ± {std:.4f}\")"
   ],
   "id": "97b57e9f8ec0e417",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/6706363/PycharmProjects/PPM_NextResource/venv/lib/python3.13/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by RandomizedSearchCV:\n",
      "{'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/6706363/PycharmProjects/PPM_NextResource/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/6706363/PycharmProjects/PPM_NextResource/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/6706363/PycharmProjects/PPM_NextResource/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8197 ± 0.0175\n",
      "Precision: 0.7569 ± 0.0264\n",
      "Recall: 0.8197 ± 0.0175\n",
      "F1-Score: 0.7713 ± 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (venv_name)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
