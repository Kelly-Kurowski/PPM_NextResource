{
 "cells": [
  {
   "cell_type": "code",
   "id": "631123e1ee20e74c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T09:48:50.120242Z",
     "start_time": "2024-12-27T09:48:43.983218Z"
    }
   },
   "source": [
    "import pm4py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Dense, LSTM\n",
    "from keras.api.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "312aa6e965ec36da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T09:48:50.133531Z",
     "start_time": "2024-12-27T09:48:50.130951Z"
    }
   },
   "source": [
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.max_colwidth', None)  # Set no limit for column width"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e987ce9af8b41e93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:17:50.374939Z",
     "start_time": "2024-12-27T13:16:03.405247Z"
    }
   },
   "source": [
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    event_log = pm4py.convert_to_dataframe(log)\n",
    "\n",
    "    return event_log\n",
    "\n",
    "event_log = import_xes(\"/Users/6706363/Downloads/BPI_Challenge_2019.xes\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 251734/251734 [01:00<00:00, 4159.88it/s]\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "759904c2e9c2e744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:17:55.895508Z",
     "start_time": "2024-12-27T13:17:54.611832Z"
    }
   },
   "source": [
    "# Assuming event_log is your DataFrame\n",
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "\n",
    "# Sort by 'time:timestamp' and 'case:concept:name'\n",
    "df = df.sort_values(by=['case:concept:name', 'time:timestamp'])\n",
    "\n",
    "df.head(n=10)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  case:concept:name                         concept:name org:resource  \\\n",
       "0  2000000000_00001                         SRM: Created     batch_00   \n",
       "1  2000000000_00001                        SRM: Complete     batch_00   \n",
       "2  2000000000_00001               SRM: Awaiting Approval     batch_00   \n",
       "3  2000000000_00001              SRM: Document Completed     batch_00   \n",
       "4  2000000000_00001  SRM: In Transfer to Execution Syst.     batch_00   \n",
       "5  2000000000_00001                         SRM: Ordered     batch_00   \n",
       "6  2000000000_00001          SRM: Change was Transmitted     batch_00   \n",
       "7  2000000000_00001           Create Purchase Order Item     user_000   \n",
       "8  2000000000_00001               Vendor creates invoice         NONE   \n",
       "9  2000000000_00001                 Record Goods Receipt     user_000   \n",
       "\n",
       "             time:timestamp  \n",
       "0 2018-01-02 12:53:00+00:00  \n",
       "1 2018-01-02 13:53:00+00:00  \n",
       "2 2018-01-02 13:53:00+00:00  \n",
       "3 2018-01-02 13:53:00+00:00  \n",
       "4 2018-01-02 13:53:00+00:00  \n",
       "5 2018-01-02 13:53:00+00:00  \n",
       "6 2018-01-02 13:53:00+00:00  \n",
       "7 2018-01-02 13:53:00+00:00  \n",
       "8 2018-01-02 22:59:00+00:00  \n",
       "9 2018-03-06 06:44:00+00:00  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>time:timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000000000_00001</td>\n",
       "      <td>SRM: Created</td>\n",
       "      <td>batch_00</td>\n",
       "      <td>2018-01-02 12:53:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000000000_00001</td>\n",
       "      <td>SRM: Complete</td>\n",
       "      <td>batch_00</td>\n",
       "      <td>2018-01-02 13:53:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000000000_00001</td>\n",
       "      <td>SRM: Awaiting Approval</td>\n",
       "      <td>batch_00</td>\n",
       "      <td>2018-01-02 13:53:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000000000_00001</td>\n",
       "      <td>SRM: Document Completed</td>\n",
       "      <td>batch_00</td>\n",
       "      <td>2018-01-02 13:53:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000000000_00001</td>\n",
       "      <td>SRM: In Transfer to Execution Syst.</td>\n",
       "      <td>batch_00</td>\n",
       "      <td>2018-01-02 13:53:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000000000_00001</td>\n",
       "      <td>SRM: Ordered</td>\n",
       "      <td>batch_00</td>\n",
       "      <td>2018-01-02 13:53:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000000000_00001</td>\n",
       "      <td>SRM: Change was Transmitted</td>\n",
       "      <td>batch_00</td>\n",
       "      <td>2018-01-02 13:53:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000000000_00001</td>\n",
       "      <td>Create Purchase Order Item</td>\n",
       "      <td>user_000</td>\n",
       "      <td>2018-01-02 13:53:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000000000_00001</td>\n",
       "      <td>Vendor creates invoice</td>\n",
       "      <td>NONE</td>\n",
       "      <td>2018-01-02 22:59:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000000000_00001</td>\n",
       "      <td>Record Goods Receipt</td>\n",
       "      <td>user_000</td>\n",
       "      <td>2018-03-06 06:44:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "9a688b0f242377e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T14:33:46.849475Z",
     "start_time": "2024-12-27T14:33:28.487922Z"
    }
   },
   "source": [
    "def create_activity_resource_sequence(df, prefix_length):\n",
    "    sequences = []\n",
    "    grouped = df.groupby('case:concept:name')\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        activities = group['concept:name'].tolist()\n",
    "        resources = group['org:resource'].tolist()\n",
    "        \n",
    "        # Only include sequences with length >= prefix_length\n",
    "        if len(activities) < prefix_length:\n",
    "            # Remove the sequence (skip appending it to the list)\n",
    "            continue\n",
    "        \n",
    "        # Truncate to the desired prefix length\n",
    "        current_activities = activities[:prefix_length]\n",
    "        current_resources = resources[:prefix_length]  # Include all resources\n",
    "        \n",
    "        # Combine activities and resources into tuples (no changes for the last activity)\n",
    "        sequence = []\n",
    "        for i in range(len(current_activities)):\n",
    "            # For all activities, include both activity and resource\n",
    "            sequence.append((current_activities[i], current_resources[i]))\n",
    "        \n",
    "        # Add the valid sequence to the list\n",
    "        sequences.append(sequence)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "# Example usage\n",
    "sequences = create_activity_resource_sequence(df,35)\n",
    "\n",
    "# Initialize a set to store unique 'R' values\n",
    "unique_R = set()\n",
    "\n",
    "# Loop through the list of sequences and extract the 'R' values\n",
    "for sequence in sequences:\n",
    "    for item in sequence:\n",
    "        # item[1] is the second element (the part with 'R')\n",
    "        unique_R.add(item[1])\n",
    "\n",
    "# The length of the set will give the number of unique occurrences of 'R'\n",
    "print(len(unique_R))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "c77b67ef8b2d3ded",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T14:34:21.023785Z",
     "start_time": "2024-12-27T14:33:46.913661Z"
    }
   },
   "source": [
    "# Prepare the list of activities and resources\n",
    "activities = []\n",
    "resources = []\n",
    "\n",
    "# Loop through sequences to gather activities and resources\n",
    "for seq in sequences:\n",
    "    for i, item in enumerate(seq):\n",
    "        activity, resource = item  # Each item is (activity, resource)\n",
    "        # Replace NaN resource with 'none'\n",
    "        if pd.isna(resource):  # Check if the resource is NaN\n",
    "            resource = 'none'\n",
    "        activities.append(activity)\n",
    "        resources.append(resource)\n",
    "\n",
    "# Fit the OneHotEncoder to the unique activities and resources\n",
    "activity_encoder = OneHotEncoder() \n",
    "resource_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit the encoder on unique activities and resources\n",
    "activity_encoder.fit([[activity] for activity in set(activities)])\n",
    "resource_encoder.fit([[resource] for resource in set(resources)])\n",
    "\n",
    "# Encode activities and resources\n",
    "encoded_sequences = []\n",
    "y_encoded = []  # List to store the one-hot encoded target resource for the last activity\n",
    "\n",
    "for seq in sequences:\n",
    "    activity_onehots = []\n",
    "    \n",
    "    # For each activity-resource pair, apply one-hot encoding\n",
    "    for i, item in enumerate(seq):\n",
    "        activity, resource = item\n",
    "        # Replace NaN resource with 'none' during encoding\n",
    "        if pd.isna(resource):  # Check if the resource is NaN\n",
    "            resource = 'none'\n",
    "        activity_onehot = activity_encoder.transform([[activity]]).toarray()\n",
    "        \n",
    "        # If it's the last item, we only encode the activity and store the resource for y\n",
    "        if i == len(seq) - 1:\n",
    "            # Add only the activity one-hot encoding\n",
    "            activity_onehots.append(activity_onehot)\n",
    "            # One-hot encode the resource and store it for prediction (y)\n",
    "            resource_onehot = resource_encoder.transform([[resource]]).toarray()\n",
    "            y_encoded.append(resource_onehot)  # Store the one-hot encoded resource\n",
    "        else:\n",
    "            # For all other activities, include both activity and resource one-hot encoding\n",
    "            resource_onehot = resource_encoder.transform([[resource]]).toarray()\n",
    "            encoded_sequence = np.hstack([activity_onehot, resource_onehot])\n",
    "            activity_onehots.append(encoded_sequence)\n",
    "    \n",
    "    # If there is more than one activity in the sequence, add the zero vector for the last resource\n",
    "    if len(seq) > 1:\n",
    "        last_activity_onehot = activity_onehots[-1]\n",
    "        last_resource_onehot = np.zeros(resource_onehot.shape)  # Zero vector for the last resource\n",
    "        activity_onehots[-1] = np.hstack([last_activity_onehot, last_resource_onehot])\n",
    "    \n",
    "    # Concatenate the encoded activities and resources for the full sequence\n",
    "    encoded_sequences.append(np.vstack(activity_onehots))\n",
    "\n",
    "X = np.array(encoded_sequences)\n",
    "y = np.array(y_encoded)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1842, 35, 171)\n",
      "(1842, 1, 143)\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T14:36:06.588093Z",
     "start_time": "2024-12-27T14:34:44.402605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize KFold with 5 splits\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Initialize the model \n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    # First LSTM layer with return_sequences=True\n",
    "    model.add(LSTM(50, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(50))\n",
    "    # Output Dense layer\n",
    "    model.add(Dense(143, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Store metrics from each fold\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Loop through the KFold splits\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Squeeze the target arrays to remove the extra dimension\n",
    "    y_train = y_train.squeeze(axis=1)\n",
    "    y_test = y_test.squeeze(axis=1)\n",
    "    \n",
    "    # Create the model for each fold\n",
    "    model = create_model()\n",
    "    \n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0, \n",
    "                        validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "    y_test_classes = np.argmax(y_test, axis=1)  # Ensure test labels are in class label format\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = np.mean(y_pred_classes == y_test_classes)\n",
    "    precision = precision_score(y_test_classes, y_pred_classes, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test_classes, y_pred_classes, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Store metrics\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Output average metrics\n",
    "print(f'Average Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}')\n",
    "print(f'Average Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}')\n",
    "print(f'Average Recall: {np.mean(recalls):.4f} ± {np.std(recalls):.4f}')\n",
    "print(f'Average F1-Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}')"
   ],
   "id": "bcef32dc7be43b5d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step\n",
      "Average Accuracy: 0.7602 ± 0.1699\n",
      "Average Precision: 0.6642 ± 0.2469\n",
      "Average Recall: 0.7602 ± 0.1699\n",
      "Average F1-Score: 0.6968 ± 0.2252\n"
     ]
    }
   ],
   "execution_count": 80
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
