{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-10T13:37:38.500797Z",
     "start_time": "2025-04-10T13:37:38.497812Z"
    }
   },
   "source": [
    "import pm4py\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:39:10.121040Z",
     "start_time": "2025-04-10T13:37:38.531333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    event_log = pm4py.convert_to_dataframe(log)\n",
    "\n",
    "    return event_log\n",
    "\n",
    "event_log = import_xes(\"/Users/6706363/Downloads/BPI_Challenge_2019.xes\")"
   ],
   "id": "ee6368015e06d4da",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 251734/251734 [00:48<00:00, 5154.09it/s]\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:39:10.954879Z",
     "start_time": "2025-04-10T13:39:10.187214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "\n",
    "df = df.sort_values(by=['org:resource', 'time:timestamp'])\n"
   ],
   "id": "7ef4132142d69c02",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:23:23.712835Z",
     "start_time": "2025-04-10T14:23:21.630994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_activity_sequences(df, prefix_length):\n",
    "    sequences = []\n",
    "    next_activities = []\n",
    "    resources = []\n",
    "\n",
    "    # Iterate through the dataframe, grouped by resource\n",
    "    for resource, resource_df in df.groupby('org:resource'):\n",
    "        activities = resource_df['concept:name'].values  # Get the activities for this resource\n",
    "\n",
    "        # Only generate sequences if there are enough activities for a valid prefix\n",
    "        if len(activities) >= prefix_length + 1:\n",
    "            prefix = activities[:prefix_length]  # Get the first 'prefix_length' activities\n",
    "            next_activity = activities[prefix_length]  # Next activity after the prefix\n",
    "            sequences.append(prefix)\n",
    "            next_activities.append(next_activity)\n",
    "            resources.append(resource)  # Append the resource for each sequence\n",
    "\n",
    "    # Convert to DataFrame with column names indicating the sequence of activities\n",
    "    sequences_df = pd.DataFrame(sequences, columns=[f\"activity_{i + 1}\" for i in range(prefix_length)])\n",
    "    sequences_df['next_activity'] = next_activities  # Add the next activity to the DataFrame\n",
    "    sequences_df['org:resource'] = resources  # Add the resource column (e.g., user_1, user_2)\n",
    "\n",
    "    return sequences_df\n",
    "\n",
    "\n",
    "# Example of how to use this function\n",
    "prefix_length = 700  # You can change this value\n",
    "sequences_df = create_activity_sequences(df, prefix_length)"
   ],
   "id": "b889d44ecc41bc28",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:23:24.141343Z",
     "start_time": "2025-04-10T14:23:23.745036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit on all unique activity values (including 'next_activity')\n",
    "all_activities = sequences_df[[f\"activity_{i+1}\" for i in range(prefix_length)] + ['next_activity']].values.flatten()\n",
    "\n",
    "label_encoder.fit(all_activities)  # Fit on the entire dataset\n",
    "\n",
    "# Apply the same encoding across all columns\n",
    "for col in [f\"activity_{i+1}\" for i in range(prefix_length)] + ['next_activity']:\n",
    "    sequences_df[col] = label_encoder.transform(sequences_df[col])\n",
    "\n",
    "sequences_df.head()"
   ],
   "id": "9cd7de8370e7a29a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   activity_1  activity_2  activity_3  activity_4  activity_5  activity_6  \\\n",
       "0          31          30          31          30          31          30   \n",
       "1          11          15          11          15          11          15   \n",
       "2          17          17          17          17          17          17   \n",
       "3          11          16          16          16          16          16   \n",
       "4          11          11          11          11          11          11   \n",
       "\n",
       "   activity_7  activity_8  activity_9  activity_10  ...  activity_693  \\\n",
       "0          31          30          31           30  ...            18   \n",
       "1          11          15          11           15  ...            15   \n",
       "2          17          17           2            2  ...            17   \n",
       "3          16          16          16           16  ...            16   \n",
       "4          11          11          11           11  ...            11   \n",
       "\n",
       "   activity_694  activity_695  activity_696  activity_697  activity_698  \\\n",
       "0            18            18            18            18            18   \n",
       "1            11            15            11            15            11   \n",
       "2            17            17            17            17            17   \n",
       "3            16            16            16            16            16   \n",
       "4            11            11            11            11            11   \n",
       "\n",
       "   activity_699  activity_700  next_activity  org:resource  \n",
       "0            18            18             18          NONE  \n",
       "1            15            11             15      batch_00  \n",
       "2            17            17             17      batch_01  \n",
       "3            16            16             16      batch_02  \n",
       "4            11            11             11      batch_03  \n",
       "\n",
       "[5 rows x 702 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_1</th>\n",
       "      <th>activity_2</th>\n",
       "      <th>activity_3</th>\n",
       "      <th>activity_4</th>\n",
       "      <th>activity_5</th>\n",
       "      <th>activity_6</th>\n",
       "      <th>activity_7</th>\n",
       "      <th>activity_8</th>\n",
       "      <th>activity_9</th>\n",
       "      <th>activity_10</th>\n",
       "      <th>...</th>\n",
       "      <th>activity_693</th>\n",
       "      <th>activity_694</th>\n",
       "      <th>activity_695</th>\n",
       "      <th>activity_696</th>\n",
       "      <th>activity_697</th>\n",
       "      <th>activity_698</th>\n",
       "      <th>activity_699</th>\n",
       "      <th>activity_700</th>\n",
       "      <th>next_activity</th>\n",
       "      <th>org:resource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>batch_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>batch_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>batch_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>batch_03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 702 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:12:30.796096Z",
     "start_time": "2025-04-10T14:03:05.173488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import LSTM, Dense\n",
    "from keras.api.callbacks import EarlyStopping\n",
    "from keras.api.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "## Experiment 1: Next Activity Prediction without activity information\n",
    "\n",
    "# Define features (prefix activities) and target (next_activity)\n",
    "X = sequences_df[[f\"activity_{i+1}\" for i in range(prefix_length)]]\n",
    "y = sequences_df['next_activity']\n",
    "\n",
    "# Identify and handle rare numeric classes\n",
    "rare_classes = y.value_counts()[y.value_counts() == 1].index.tolist()\n",
    "\n",
    "# Handle rare class scenario by replacing rare classes with a placeholder value (e.g., -1)\n",
    "if len(rare_classes) > 0:\n",
    "    y = y.replace(rare_classes, -1)  # Replace rare classes with -1 or some placeholder value\n",
    "elif len(rare_classes) == 1:\n",
    "    # Duplicate the rare class to avoid error\n",
    "    y = y.append(pd.Series(rare_classes * 2)).reset_index(drop=True)\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# One-hot encode target labels\n",
    "y_encoded = to_categorical(y_encoded)\n",
    "\n",
    "# Reshape features to 3D array for LSTM input\n",
    "X_reshaped = np.array(X)\n",
    "X_reshaped = X_reshaped.reshape((X_reshaped.shape[0], X_reshaped.shape[1], 1))  # (samples, timesteps, features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Build the LSTM model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(y_encoded.shape[1], activation='softmax'))  # 'softmax' for multi-class classification\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Implement Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Initialize KFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Prepare lists to store metrics\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(X_train, np.argmax(y_train, axis=1)):\n",
    "    X_train_cv, X_val_cv = X_train[train_index], X_train[val_index]\n",
    "    y_train_cv, y_val_cv = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # Build and train the model for each fold\n",
    "    model = build_model()\n",
    "    model.fit(X_train_cv, y_train_cv, epochs=50, batch_size=32, validation_data=(X_val_cv, y_val_cv), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_prob = model.predict(X_val_cv)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Convert one-hot encoded validation labels back to single class values\n",
    "    y_val_decoded = np.argmax(y_val_cv, axis=1)\n",
    "\n",
    "    # Calculate metrics for this fold\n",
    "    accuracy = accuracy_score(y_val_decoded, y_pred)\n",
    "    precision = precision_score(y_val_decoded, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_val_decoded, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_val_decoded, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate standard deviation for each metric\n",
    "accuracy_sd = np.std(accuracies)\n",
    "precision_sd = np.std(precisions)\n",
    "recall_sd = np.std(recalls)\n",
    "f1_sd = np.std(f1_scores)\n",
    "\n",
    "# Calculate mean for each metric (cross-validation average)\n",
    "accuracy_mean = np.mean(accuracies)\n",
    "precision_mean = np.mean(precisions)\n",
    "recall_mean = np.mean(recalls)\n",
    "f1_mean = np.mean(f1_scores)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Accuracy: {accuracy_mean:.4f} (±{accuracy_sd:.4f})\")\n",
    "print(f\"Mean Precision: {precision_mean:.4f} (±{precision_sd:.4f})\")\n",
    "print(f\"Mean Recall: {recall_mean:.4f} (±{recall_sd:.4f})\")\n",
    "print(f\"Mean F1-Score: {f1_mean:.4f} (±{f1_sd:.4f})\")\n"
   ],
   "id": "3f3ce7955c06e4a1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[61], line 71\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;66;03m# Build and train the model for each fold\u001B[39;00m\n\u001B[1;32m     70\u001B[0m model \u001B[38;5;241m=\u001B[39m build_model()\n\u001B[0;32m---> 71\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_cv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_cv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_val_cv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val_cv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;66;03m# Make predictions\u001B[39;00m\n\u001B[1;32m     74\u001B[0m y_pred_prob \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_val_cv)\n",
      "File \u001B[0;32m~/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    369\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[1;32m    370\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m--> 371\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    372\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(step, logs)\n\u001B[1;32m    373\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n",
      "File \u001B[0;32m~/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001B[0m, in \u001B[0;36mTensorFlowTrainer._make_function.<locals>.function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfunction\u001B[39m(iterator):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[1;32m    217\u001B[0m         iterator, (tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mIterator, tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mDistributedIterator)\n\u001B[1;32m    218\u001B[0m     ):\n\u001B[0;32m--> 219\u001B[0m         opt_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmulti_step_on_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_outputs\u001B[38;5;241m.\u001B[39mhas_value():\n\u001B[1;32m    221\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n\u001B[1;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1683\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1681\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1682\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1683\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1684\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1685\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1686\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1687\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1688\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1689\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1690\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1691\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1692\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1693\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1697\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1698\u001B[0m   )\n",
      "File \u001B[0;32m~/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:03:12.670900Z",
     "start_time": "2025-04-10T14:03:11.159664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Experiment 2: Next Activity Prediction with activity information\n",
    "import binary_classifier\n",
    "\n",
    "ra_diversity_matrix = binary_classifier.create_diversity_matrix(event_log)\n",
    "ra_diversity_matrix_binary = ra_diversity_matrix.copy()\n",
    "# Apply a binary transformation: any count > 0 becomes 1 (yes), else 0 (no)\n",
    "ra_diversity_matrix_binary.iloc[:, 1:] = (ra_diversity_matrix_binary.iloc[:, 1:] > 0).astype(int)\n",
    "\n",
    "activities = ra_diversity_matrix.columns[1:].tolist()  # Convert to a list of activities\n",
    "\n",
    "binary_activities = ra_diversity_matrix_binary.iloc[:, :]"
   ],
   "id": "752fcbb23903c06b",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:03:12.702670Z",
     "start_time": "2025-04-10T14:03:12.680175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Keep only resources that are in sequences_df\n",
    "filtered_binary_activities = binary_activities[binary_activities['org:resource'].isin(sequences_df['org:resource'])]\n",
    "\n",
    "# Reset index to ensure proper alignment\n",
    "filtered_binary_activities = filtered_binary_activities.reset_index(drop=True)\n",
    "sequences_df = sequences_df.reset_index(drop=True)\n",
    "\n",
    "# Merge again\n",
    "merged_df = pd.concat([sequences_df, filtered_binary_activities], axis=1)"
   ],
   "id": "6fdf6d69b0cade17",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:05:25.007491Z",
     "start_time": "2025-04-10T14:03:13.051549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import LSTM, Dense\n",
    "from keras.api.callbacks import EarlyStopping\n",
    "from keras.api.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = merged_df[[f\"activity_{i+1}\" for i in range(prefix_length)] + activities]\n",
    "y = merged_df['next_activity']\n",
    "\n",
    "# Identify and handle rare numeric classes\n",
    "rare_classes = y.value_counts()[y.value_counts() == 1].index.tolist()\n",
    "\n",
    "# Handle rare class scenario by replacing rare classes with a placeholder value (e.g., -1)\n",
    "if len(rare_classes) > 0:\n",
    "    y = y.replace(rare_classes, -1)  # Replace rare classes with -1 or some placeholder value\n",
    "elif len(rare_classes) == 1:\n",
    "    # Duplicate the rare class to avoid error\n",
    "    y = y.append(pd.Series(rare_classes * 2)).reset_index(drop=True)\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# One-hot encode target labels\n",
    "y_encoded = to_categorical(y_encoded)\n",
    "\n",
    "# Reshape features to 3D array for LSTM input\n",
    "X_reshaped = np.array(X)\n",
    "X_reshaped = X_reshaped.reshape((X_reshaped.shape[0], X_reshaped.shape[1], 1))  # (samples, timesteps, features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Build the LSTM model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(y_encoded.shape[1], activation='softmax'))  # 'softmax' for multi-class classification\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Implement Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Initialize KFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Prepare lists to store metrics\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(X_train, np.argmax(y_train, axis=1)):\n",
    "    X_train_cv, X_val_cv = X_train[train_index], X_train[val_index]\n",
    "    y_train_cv, y_val_cv = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # Build and train the model for each fold\n",
    "    model = build_model()\n",
    "    model.fit(X_train_cv, y_train_cv, epochs=50, batch_size=32, validation_data=(X_val_cv, y_val_cv), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_prob = model.predict(X_val_cv)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Convert one-hot encoded validation labels back to single class values\n",
    "    y_val_decoded = np.argmax(y_val_cv, axis=1)\n",
    "\n",
    "    # Calculate metrics for this fold\n",
    "    accuracy = accuracy_score(y_val_decoded, y_pred)\n",
    "    precision = precision_score(y_val_decoded, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_val_decoded, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_val_decoded, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate standard deviation for each metric\n",
    "accuracy_sd = np.std(accuracies)\n",
    "precision_sd = np.std(precisions)\n",
    "recall_sd = np.std(recalls)\n",
    "f1_sd = np.std(f1_scores)\n",
    "\n",
    "# Calculate mean for each metric (cross-validation average)\n",
    "accuracy_mean = np.mean(accuracies)\n",
    "precision_mean = np.mean(precisions)\n",
    "recall_mean = np.mean(recalls)\n",
    "f1_mean = np.mean(f1_scores)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Accuracy: {accuracy_mean:.4f} (±{accuracy_sd:.4f})\")\n",
    "print(f\"Mean Precision: {precision_mean:.4f} (±{precision_sd:.4f})\")\n",
    "print(f\"Mean Recall: {recall_mean:.4f} (±{recall_sd:.4f})\")\n",
    "print(f\"Mean F1-Score: {f1_mean:.4f} (±{f1_sd:.4f})\")"
   ],
   "id": "3346e2bcc0ed51da",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 175ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 196ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 202ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 176ms/step\n",
      "Mean Accuracy: 0.5749 (±0.1597)\n",
      "Mean Precision: 0.3851 (±0.2033)\n",
      "Mean Recall: 0.5749 (±0.1597)\n",
      "Mean F1-Score: 0.4511 (±0.2014)\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "11b4c145a4a4b252"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:23:27.767143Z",
     "start_time": "2025-04-10T14:23:27.746386Z"
    }
   },
   "cell_type": "code",
   "source": "sequences_df = sequences_df.drop(columns=['org:resource'])",
   "id": "ed97b89a9fb8f5d8",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:17:18.857954Z",
     "start_time": "2025-04-10T14:16:47.119062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import LSTM, Dense\n",
    "from keras.api.callbacks import EarlyStopping\n",
    "\n",
    "# Get unique activities from the dataset\n",
    "unique_activities = sorted(set(sequences_df.values.flatten()))\n",
    "\n",
    "# Generate all possible transitions\n",
    "all_possible_transitions = {(a, b) for a in unique_activities for b in unique_activities}\n",
    "\n",
    "# Create a list to store transition count dictionaries\n",
    "transition_counts = []\n",
    "\n",
    "# Iterate through each row to count transitions\n",
    "for _, row in sequences_df.iterrows():\n",
    "    transitions = defaultdict(int)\n",
    "    activities = row.dropna().values  # Extract non-null activities\n",
    "\n",
    "    # Count actual transitions\n",
    "    for i in range(len(activities) - 1):\n",
    "        transition = (activities[i], activities[i + 1])\n",
    "        transitions[transition] += 1\n",
    "\n",
    "    # Ensure every possible transition exists (fill with 0 if not present)\n",
    "    row_counts = {t: transitions.get(t, 0) for t in all_possible_transitions}\n",
    "    transition_counts.append(row_counts)\n",
    "\n",
    "# Convert list of transition count dictionaries to a DataFrame\n",
    "transitions_df = pd.DataFrame(transition_counts)\n",
    "\n",
    "# Rename columns to string format (e.g., '0->0', '0->1', etc.)\n",
    "transitions_df.columns = [f\"{a}->{b}\" for a, b in transitions_df.columns]\n",
    "\n",
    "# Merge with original DataFrame\n",
    "result_df = pd.concat([sequences_df, transitions_df], axis=1)\n",
    "\n",
    "X = result_df.drop(columns=['next_activity'])\n",
    "y = result_df['next_activity']\n",
    "\n",
    "# Identify rare classes (fewer than 2 instances)\n",
    "rare_classes = y.value_counts()[y.value_counts() < 2].index.tolist()\n",
    "\n",
    "# Replace rare classes with -1\n",
    "if len(rare_classes) > 0:\n",
    "    y = y.replace(rare_classes, -1)\n",
    "\n",
    "    # Ensure at least two instances of -1 for StratifiedKFold\n",
    "    if (y == -1).sum() == 1:\n",
    "        y = pd.concat([y, pd.Series([-1])], ignore_index=True)\n",
    "        X = pd.concat([X, X.iloc[[0]]], ignore_index=True)  # Duplicate one row in X\n",
    "\n",
    "\n",
    "# One-hot encode target variable\n",
    "y_encoded = pd.get_dummies(y).values  # Convert categorical labels to one-hot encoding\n",
    "\n",
    "# Feature selection\n",
    "X_selected = SelectKBest(mutual_info_classif, k=20).fit_transform(X, y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Reshape X_train and X_test to 3D for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))  # (samples, timesteps=1, features)\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the LSTM model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(1, X_train.shape[2])))  # Fix input shape\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(y_encoded.shape[1], activation='softmax'))  # Ensure correct output size\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Implement Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Initialize KFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Prepare lists to store metrics\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(X_train, y_train.argmax(axis=1)):\n",
    "    X_train_cv, X_val_cv = X_train[train_index], X_train[val_index]\n",
    "    y_train_cv, y_val_cv = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # Build and train the model for each fold\n",
    "    model = build_model()\n",
    "    model.fit(X_train_cv, y_train_cv, epochs=50, batch_size=32, validation_data=(X_val_cv, y_val_cv), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_prob = model.predict(X_val_cv)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    \n",
    "    # Convert one-hot encoded validation labels back to single class values\n",
    "    y_val_decoded = np.argmax(y_val_cv, axis=1)\n",
    "\n",
    "    # Calculate metrics for this fold\n",
    "    accuracy = accuracy_score(y_val_decoded, y_pred)\n",
    "    precision = precision_score(y_val_decoded, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_val_decoded, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_val_decoded, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate standard deviation for each metric\n",
    "accuracy_sd = np.std(accuracies)\n",
    "precision_sd = np.std(precisions)\n",
    "recall_sd = np.std(recalls)\n",
    "f1_sd = np.std(f1_scores)\n",
    "\n",
    "# Calculate mean for each metric (cross-validation average)\n",
    "accuracy_mean = np.mean(accuracies)\n",
    "precision_mean = np.mean(precisions)\n",
    "recall_mean = np.mean(recalls)\n",
    "f1_mean = np.mean(f1_scores)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Accuracy: {accuracy_mean:.4f} (±{accuracy_sd:.4f})\")\n",
    "print(f\"Mean Precision: {precision_mean:.4f} (±{precision_sd:.4f})\")\n",
    "print(f\"Mean Recall: {recall_mean:.4f} (±{recall_sd:.4f})\")\n",
    "print(f\"Mean F1-Score: {f1_mean:.4f} (±{f1_sd:.4f})\")\n"
   ],
   "id": "89eab19008e4768f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 117ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 118ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 113ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 117ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 114ms/step\n",
      "Mean Accuracy: 0.6693 (±0.0384)\n",
      "Mean Precision: 0.4910 (±0.0465)\n",
      "Mean Recall: 0.6693 (±0.0384)\n",
      "Mean F1-Score: 0.5608 (±0.0442)\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:24:08.127857Z",
     "start_time": "2025-04-10T14:23:35.662574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Experiment 5: Next Activity Prediction with activity transitions count and repeat pattern features\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import LSTM, Dense\n",
    "from keras.api.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Get unique activities from the dataset\n",
    "unique_activities = sorted(set(sequences_df.values.flatten()))\n",
    "\n",
    "# Generate all possible transitions\n",
    "all_possible_transitions = {(a, b) for a in unique_activities for b in unique_activities}\n",
    "\n",
    "# Create a list to store transition count dictionaries\n",
    "transition_counts = []\n",
    "repeat_pattern_features = []\n",
    "\n",
    "# Iterate through each row to count transitions and compute repeat features\n",
    "for _, row in sequences_df.iterrows():\n",
    "    transitions = defaultdict(int)\n",
    "    activities = row.dropna().values  # Non-null activities\n",
    "    \n",
    "    # --- Transition Counting ---\n",
    "    for i in range(len(activities) - 1):\n",
    "        transition = (activities[i], activities[i + 1])\n",
    "        transitions[transition] += 1\n",
    "    row_counts = {t: transitions.get(t, 0) for t in all_possible_transitions}\n",
    "    transition_counts.append(row_counts)\n",
    "    \n",
    "    # --- Repeat Pattern Features ---\n",
    "    max_run = 1\n",
    "    current_run = 1\n",
    "    run_lengths = []\n",
    "    repetitive_activities = set()\n",
    "    \n",
    "    for i in range(1, len(activities)):\n",
    "        if activities[i] == activities[i - 1]:\n",
    "            current_run += 1\n",
    "            repetitive_activities.add(activities[i])\n",
    "        else:\n",
    "            run_lengths.append(current_run)\n",
    "            current_run = 1\n",
    "    run_lengths.append(current_run)  # Add final run\n",
    "    \n",
    "    max_run_length = max(run_lengths)\n",
    "    avg_run_length = np.mean(run_lengths)\n",
    "    num_runs = len(run_lengths)\n",
    "    num_repetitive_activities = len(repetitive_activities)\n",
    "\n",
    "    repeat_pattern_features.append({\n",
    "        'max_run_length': max_run_length,\n",
    "        'avg_run_length': avg_run_length,\n",
    "        'num_runs': num_runs,\n",
    "        'num_repetitive_activities': num_repetitive_activities\n",
    "    })\n",
    "\n",
    "# Convert to DataFrames\n",
    "transitions_df = pd.DataFrame(transition_counts)\n",
    "transitions_df.columns = [f\"{a}->{b}\" for a, b in transitions_df.columns]\n",
    "\n",
    "repeat_df = pd.DataFrame(repeat_pattern_features)\n",
    "\n",
    "# Merge everything\n",
    "result_df = pd.concat([sequences_df, transitions_df, repeat_df], axis=1)\n",
    "\n",
    "# Compute mutual information scores for repeat pattern features\n",
    "mi_scores = mutual_info_classif(repeat_df, result_df['next_activity'], discrete_features=True)\n",
    "feature_scores = dict(zip(repeat_df.columns, mi_scores))\n",
    "sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nMutual Information Scores for Repeat Pattern Features:\")\n",
    "for feature, score in sorted_features:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "\n",
    "# Remove the least important features based on MI scores (i.e., num_repetitive_activities, max_run_length)\n",
    "repeat_df = repeat_df.drop(columns=['num_repetitive_activities', 'max_run_length'])\n",
    "\n",
    "# Merge updated repeat_df with result_df\n",
    "result_df = pd.concat([sequences_df, transitions_df, repeat_df], axis=1)\n",
    "\n",
    "# Prepare features and labels\n",
    "X = result_df.drop(columns=['next_activity'])\n",
    "y = result_df['next_activity']\n",
    "\n",
    "# Identify rare classes (fewer than 2 instances)\n",
    "rare_classes = y.value_counts()[y.value_counts() < 2].index.tolist()\n",
    "\n",
    "# Replace rare classes with -1\n",
    "if len(rare_classes) > 0:\n",
    "    y = y.replace(rare_classes, -1)\n",
    "\n",
    "    # Ensure at least two instances of -1 for StratifiedKFold\n",
    "    if (y == -1).sum() == 1:\n",
    "        y = pd.concat([y, pd.Series([-1])], ignore_index=True)\n",
    "        X = pd.concat([X, X.iloc[[0]]], ignore_index=True)  # Duplicate one row in X\n",
    "        \n",
    "# Feature selection\n",
    "X_selected = SelectKBest(mutual_info_classif, k=20).fit_transform(X, y)\n",
    "\n",
    "# One-hot encode target variable\n",
    "y_encoded = pd.get_dummies(y).values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Reshape X_train and X_test to 3D for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))  # (samples, timesteps=1, features)\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the LSTM model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(1, X_train.shape[2])))  # Fix input shape\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(y_encoded.shape[1], activation='softmax'))  # Ensure correct output size\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Implement Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Initialize KFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Prepare lists to store metrics\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(X_train, y_train.argmax(axis=1)):\n",
    "    X_train_cv, X_val_cv = X_train[train_index], X_train[val_index]\n",
    "    y_train_cv, y_val_cv = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # Build and train the model for each fold\n",
    "    model = build_model()\n",
    "    model.fit(X_train_cv, y_train_cv, epochs=50, batch_size=32, validation_data=(X_val_cv, y_val_cv), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_prob = model.predict(X_val_cv)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    \n",
    "    # Convert one-hot encoded validation labels back to single class values\n",
    "    y_val_decoded = np.argmax(y_val_cv, axis=1)\n",
    "\n",
    "    # Calculate metrics for this fold\n",
    "    accuracy = accuracy_score(y_val_decoded, y_pred)\n",
    "    precision = precision_score(y_val_decoded, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_val_decoded, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_val_decoded, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate standard deviation for each metric\n",
    "accuracy_sd = np.std(accuracies)\n",
    "precision_sd = np.std(precisions)\n",
    "recall_sd = np.std(recalls)\n",
    "f1_sd = np.std(f1_scores)\n",
    "\n",
    "# Calculate mean for each metric (cross-validation average)\n",
    "accuracy_mean = np.mean(accuracies)\n",
    "precision_mean = np.mean(precisions)\n",
    "recall_mean = np.mean(recalls)\n",
    "f1_mean = np.mean(f1_scores)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Accuracy: {accuracy_mean:.4f} (±{accuracy_sd:.4f})\")\n",
    "print(f\"Mean Precision: {precision_mean:.4f} (±{precision_sd:.4f})\")\n",
    "print(f\"Mean Recall: {recall_mean:.4f} (±{recall_sd:.4f})\")\n",
    "print(f\"Mean F1-Score: {f1_mean:.4f} (±{f1_sd:.4f})\")\n"
   ],
   "id": "be81e00865cf0781",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/sklearn/metrics/cluster/_supervised.py:59: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and multiclass values for target\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mutual Information Scores for Repeat Pattern Features:\n",
      "max_run_length: 1.2873\n",
      "num_runs: 1.1414\n",
      "avg_run_length: 1.1414\n",
      "num_repetitive_activities: 0.4906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 114ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 115ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 112ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 116ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/6706363/PycharmProjects/PPM_NextResource/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 119ms/step\n",
      "Mean Accuracy: 0.6328 (±0.0481)\n",
      "Mean Precision: 0.4690 (±0.0556)\n",
      "Mean Recall: 0.6328 (±0.0481)\n",
      "Mean F1-Score: 0.5312 (±0.0535)\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3e2e21166adbd6a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
