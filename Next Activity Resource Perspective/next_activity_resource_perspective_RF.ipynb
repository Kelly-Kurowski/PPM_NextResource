{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import pm4py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    event_log = pm4py.convert_to_dataframe(log)\n",
    "\n",
    "    return event_log\n",
    "\n",
    "event_log = import_xes(\"/Users/6706363/Downloads/BPI_Challenge_2019.xes\")\n"
   ],
   "id": "685f1460aa6ad52a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = event_log[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "\n",
    "df = df.sort_values(by=['org:resource', 'time:timestamp'])\n"
   ],
   "id": "4e1e8ef5a2f867ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_activity_sequences(df, prefix_length):\n",
    "    sequences = []\n",
    "    next_activities = []\n",
    "    resources = []\n",
    "\n",
    "    # Iterate through the dataframe, grouped by resource\n",
    "    for resource, resource_df in df.groupby('org:resource'):\n",
    "        activities = resource_df['concept:name'].values  # Get the activities for this resource\n",
    "        \n",
    "        # Only generate sequences if there are enough activities for a valid prefix\n",
    "        if len(activities) >= prefix_length + 1:\n",
    "            prefix = activities[:prefix_length]  # Get the first 'prefix_length' activities\n",
    "            next_activity = activities[prefix_length]  # Next activity after the prefix\n",
    "            sequences.append(prefix)\n",
    "            next_activities.append(next_activity)\n",
    "            resources.append(resource)  # Append the resource for each sequence\n",
    "\n",
    "    # Convert to DataFrame with column names indicating the sequence of activities\n",
    "    sequences_df = pd.DataFrame(sequences, columns=[f\"activity_{i+1}\" for i in range(prefix_length)])\n",
    "    sequences_df['next_activity'] = next_activities  # Add the next activity to the DataFrame\n",
    "    sequences_df['org:resource'] = resources  # Add the resource column (e.g., user_1, user_2)\n",
    "\n",
    "    return sequences_df\n",
    "\n",
    "# Example of how to use this function\n",
    "prefix_length = 700  # You can change this value\n",
    "sequences_df = create_activity_sequences(df, prefix_length)"
   ],
   "id": "58551d90c3e137df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit on all unique activity values (including 'next_activity')\n",
    "all_activities = sequences_df[[f\"activity_{i+1}\" for i in range(prefix_length)] + ['next_activity']].values.flatten()\n",
    "label_encoder.fit(all_activities)  # Fit on the entire dataset\n",
    "\n",
    "# Apply the same encoding across all columns\n",
    "for col in [f\"activity_{i+1}\" for i in range(prefix_length)] + ['next_activity']:\n",
    "    sequences_df[col] = label_encoder.transform(sequences_df[col])\n",
    "\n",
    "# Store mappings for decoding later\n",
    "activity_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "inverse_activity_mapping = {v: k for k, v in activity_mapping.items()}\n",
    "\n",
    "# Show the first 10 rows of the resulting dataframe\n",
    "sequences_df.head(n=10)\n"
   ],
   "id": "3188b97f3b717a9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Experiment 1: Next Activity Prediction without activity information\n",
    "\n",
    "# Define features (prefix activities) and target (next_activity)\n",
    "X = sequences_df[[f\"activity_{i+1}\" for i in range(prefix_length)]]\n",
    "y = sequences_df['next_activity']\n",
    "\n",
    "# Identify and handle rare numeric classes\n",
    "rare_classes = y.value_counts()[y.value_counts() == 1].index.tolist()\n",
    "\n",
    "if len(rare_classes) == 1:\n",
    "    rare_class = rare_classes[0]\n",
    "    rare_class_rows = X[y == rare_class]\n",
    "    X = pd.concat([X, rare_class_rows], axis=0)\n",
    "    y = pd.concat([y, pd.Series([rare_class] * len(rare_class_rows))], axis=0)\n",
    "else:\n",
    "    new_label = max(y) + 1\n",
    "    y = y.replace(rare_classes, new_label)\n",
    "    others_rows = X[y.isin(rare_classes)]\n",
    "    X = pd.concat([X, others_rows], axis=0)\n",
    "    y = pd.concat([y, pd.Series([new_label] * len(others_rows))], axis=0)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Train Random Forest Classifier with GridSearchCV\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Print best parameters\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate model on the final test set\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Compute cross-validated scores for standard deviation calculation\n",
    "cv_results = cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "accuracy_sd = np.std(cv_results)\n",
    "precision_sd = np.std(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='precision_weighted'))\n",
    "recall_sd = np.std(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='recall_weighted'))\n",
    "f1_sd = np.std(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='f1_weighted'))\n",
    "\n",
    "# Print results with standard deviation\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f} (±{accuracy_sd:.4f})\")\n",
    "print(f\"Precision: {precision:.4f} (±{precision_sd:.4f})\")\n",
    "print(f\"Recall: {recall:.4f} (±{recall_sd:.4f})\")\n",
    "print(f\"F1-Score: {f1:.4f} (±{f1_sd:.4f})\")"
   ],
   "id": "e4f356b213a91189",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import binary_classifier\n",
    "\n",
    "ra_diversity_matrix = binary_classifier.create_diversity_matrix(event_log)\n",
    "ra_diversity_matrix_binary = ra_diversity_matrix.copy()\n",
    "# Apply a binary transformation: any count > 0 becomes 1 (yes), else 0 (no)\n",
    "ra_diversity_matrix_binary.iloc[:, 1:] = (ra_diversity_matrix_binary.iloc[:, 1:] > 0).astype(int)\n",
    "\n",
    "activities = ra_diversity_matrix.columns[1:].tolist()  # Convert to a list of activities\n",
    "\n",
    "binary_activities = ra_diversity_matrix_binary.iloc[:, :]\n"
   ],
   "id": "371bc2967b59aa93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Keep only resources that are in sequences_df\n",
    "filtered_binary_activities = binary_activities[binary_activities['org:resource'].isin(sequences_df['org:resource'])]\n",
    "\n",
    "# Reset index to ensure proper alignment\n",
    "filtered_binary_activities = filtered_binary_activities.reset_index(drop=True)\n",
    "sequences_df = sequences_df.reset_index(drop=True)\n",
    "\n",
    "# Merge again\n",
    "merged_df = pd.concat([sequences_df, filtered_binary_activities], axis=1)\n",
    "\n",
    "merged_df.head(n=10)\n",
    "\n"
   ],
   "id": "f44609b6e1b91278",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Experiment 2: Next Activity Prediction with activity information\n",
    "\n",
    "X = merged_df[activities + [f\"activity_{i+1}\" for i in range(prefix_length)]]\n",
    "y = merged_df['next_activity']\n",
    "\n",
    "merged_df.head(n=10)\n",
    "\n",
    "# Identify and handle rare numeric classes\n",
    "rare_classes = y.value_counts()[y.value_counts() == 1].index.tolist()\n",
    "\n",
    "if len(rare_classes) == 1:\n",
    "    rare_class = rare_classes[0]\n",
    "    rare_class_rows = X[y == rare_class]\n",
    "    X = pd.concat([X, rare_class_rows], axis=0)\n",
    "    y = pd.concat([y, pd.Series([rare_class] * len(rare_class_rows))], axis=0)\n",
    "else:\n",
    "    new_label = max(y) + 1\n",
    "    y = y.replace(rare_classes, new_label)\n",
    "    others_rows = X[y.isin(rare_classes)]\n",
    "    X = pd.concat([X, others_rows], axis=0)\n",
    "    y = pd.concat([y, pd.Series([new_label] * len(others_rows))], axis=0)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Train Random Forest Classifier with GridSearchCV\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Print best parameters\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate model on the final test set\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Compute cross-validated scores for standard deviation calculation\n",
    "cv_results = cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "accuracy_sd = np.std(cv_results)\n",
    "precision_sd = np.std(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='precision_weighted'))\n",
    "recall_sd = np.std(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='recall_weighted'))\n",
    "f1_sd = np.std(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='f1_weighted'))\n",
    "\n",
    "# Print results with standard deviation\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f} (±{accuracy_sd:.4f})\")\n",
    "print(f\"Precision: {precision:.4f} (±{precision_sd:.4f})\")\n",
    "print(f\"Recall: {recall:.4f} (±{recall_sd:.4f})\")\n",
    "print(f\"F1-Score: {f1:.4f} (±{f1_sd:.4f})\")"
   ],
   "id": "5a2e1579b643969d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Experiment 3: Next Activity Prediction with activity transitions count**",
   "id": "110f3141208734f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sequences_df = sequences_df.drop(columns=['org:resource'])",
   "id": "22c4f51df649e7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Experiment 3: Next Activity Prediction with activity transitions count\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Get unique activities from the dataset\n",
    "unique_activities = sorted(set(sequences_df.values.flatten()))\n",
    "\n",
    "# Generate all possible transitions\n",
    "all_possible_transitions = {(a, b) for a in unique_activities for b in unique_activities}\n",
    "\n",
    "# Create a list to store transition count dictionaries\n",
    "transition_counts = []\n",
    "\n",
    "# Iterate through each row to count transitions\n",
    "for _, row in sequences_df.iterrows():\n",
    "    transitions = defaultdict(int)\n",
    "    activities = row.dropna().values  # Extract non-null activities\n",
    "\n",
    "    # Count actual transitions\n",
    "    for i in range(len(activities) - 1):\n",
    "        transition = (activities[i], activities[i + 1])\n",
    "        transitions[transition] += 1\n",
    "\n",
    "    # Ensure every possible transition exists (fill with 0 if not present)\n",
    "    row_counts = {t: transitions.get(t, 0) for t in all_possible_transitions}\n",
    "    transition_counts.append(row_counts)\n",
    "\n",
    "# Convert list of transition count dictionaries to a DataFrame\n",
    "transitions_df = pd.DataFrame(transition_counts)\n",
    "\n",
    "# Rename columns to string format (e.g., '0->0', '0->1', etc.)\n",
    "transitions_df.columns = [f\"{a}->{b}\" for a, b in transitions_df.columns]\n",
    "\n",
    "# Merge with original DataFrame\n",
    "result_df = pd.concat([sequences_df, transitions_df], axis=1)\n",
    "\n",
    "X = result_df.drop(columns=['next_activity'])\n",
    "y = result_df['next_activity']\n",
    "\n",
    "# Identify and handle rare numeric classes\n",
    "rare_classes = y.value_counts()[y.value_counts() == 1].index.tolist()\n",
    "\n",
    "if len(rare_classes) == 1:\n",
    "    rare_class = rare_classes[0]\n",
    "    rare_class_rows = X[y == rare_class]\n",
    "    X = pd.concat([X, rare_class_rows], axis=0)\n",
    "    y = pd.concat([y, pd.Series([rare_class] * len(rare_class_rows))], axis=0)\n",
    "else:\n",
    "    new_label = max(y) + 1\n",
    "    y = y.replace(rare_classes, new_label)\n",
    "    others_rows = X[y.isin(rare_classes)]\n",
    "    X = pd.concat([X, others_rows], axis=0)\n",
    "    y = pd.concat([y, pd.Series([new_label] * len(others_rows))], axis=0)\n",
    "\n",
    "X_selected = SelectKBest(mutual_info_classif, k=20).fit_transform(X, y)\n",
    "\n",
    "# Split data into training and testing sets with selected features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300], \n",
    "    'max_depth': [None, 10, 20, 30], \n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4], \n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Train Random Forest Classifier with GridSearchCV\n",
    "rf_model_selected = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf_model_selected, param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Print best parameters\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate model on the final test set\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Compute cross-validated scores for standard deviation calculation\n",
    "cv_results = cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "accuracy_sd = np.std(cv_results)\n",
    "precision_sd = np.std(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='precision_weighted'))\n",
    "recall_sd = np.std(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='recall_weighted'))\n",
    "f1_sd = np.std(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='f1_weighted'))\n",
    "\n",
    "# Print results with standard deviation\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f} (±{accuracy_sd:.4f})\")\n",
    "print(f\"Precision: {precision:.4f} (±{precision_sd:.4f})\")\n",
    "print(f\"Recall: {recall:.4f} (±{recall_sd:.4f})\")\n",
    "print(f\"F1-Score: {f1:.4f} (±{f1_sd:.4f})\")\n"
   ],
   "id": "2e82a1f2bcc78c10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Experiment 4: Next Activity Prediction with activity transitions count and repeat pattern features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get unique activities from the dataset\n",
    "unique_activities = sorted(set(sequences_df.values.flatten()))\n",
    "\n",
    "# Generate all possible transitions\n",
    "all_possible_transitions = {(a, b) for a in unique_activities for b in unique_activities}\n",
    "\n",
    "# Create a list to store transition count dictionaries\n",
    "transition_counts = []\n",
    "repeat_pattern_features = []\n",
    "\n",
    "# Iterate through each row to count transitions and compute repeat features\n",
    "for _, row in sequences_df.iterrows():\n",
    "    transitions = defaultdict(int)\n",
    "    activities = row.dropna().values  # Non-null activities\n",
    "    \n",
    "    # --- Transition Counting ---\n",
    "    for i in range(len(activities) - 1):\n",
    "        transition = (activities[i], activities[i + 1])\n",
    "        transitions[transition] += 1\n",
    "    row_counts = {t: transitions.get(t, 0) for t in all_possible_transitions}\n",
    "    transition_counts.append(row_counts)\n",
    "    \n",
    "    # --- Repeat Pattern Features ---\n",
    "    max_run = 1\n",
    "    current_run = 1\n",
    "    run_lengths = []\n",
    "    repetitive_activities = set()\n",
    "    \n",
    "    for i in range(1, len(activities)):\n",
    "        if activities[i] == activities[i - 1]:\n",
    "            current_run += 1\n",
    "            repetitive_activities.add(activities[i])\n",
    "        else:\n",
    "            run_lengths.append(current_run)\n",
    "            current_run = 1\n",
    "    run_lengths.append(current_run)  # Add final run\n",
    "    \n",
    "    max_run_length = max(run_lengths)\n",
    "    avg_run_length = np.mean(run_lengths)\n",
    "    num_runs = len(run_lengths)\n",
    "    num_repetitive_activities = len(repetitive_activities)\n",
    "\n",
    "    repeat_pattern_features.append({\n",
    "        'max_run_length': max_run_length,\n",
    "        'avg_run_length': avg_run_length,\n",
    "        'num_runs': num_runs,\n",
    "        'num_repetitive_activities': num_repetitive_activities\n",
    "    })\n",
    "\n",
    "# Convert to DataFrames\n",
    "transitions_df = pd.DataFrame(transition_counts)\n",
    "transitions_df.columns = [f\"{a}->{b}\" for a, b in transitions_df.columns]\n",
    "\n",
    "repeat_df = pd.DataFrame(repeat_pattern_features)\n",
    "\n",
    "# Merge everything\n",
    "result_df = pd.concat([sequences_df, transitions_df, repeat_df], axis=1)\n",
    "\n",
    "# Compute mutual information scores for repeat pattern features\n",
    "mi_scores = mutual_info_classif(repeat_df, result_df['next_activity'], discrete_features=True)\n",
    "feature_scores = dict(zip(repeat_df.columns, mi_scores))\n",
    "sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nMutual Information Scores for Repeat Pattern Features:\")\n",
    "for feature, score in sorted_features:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "\n",
    "# Remove the least important features based on MI scores (i.e., num_repetitive_activities, max_run_length)\n",
    "repeat_df = repeat_df.drop(columns=['num_repetitive_activities', 'max_run_length'])\n",
    "\n",
    "# Merge updated repeat_df with result_df\n",
    "result_df = pd.concat([sequences_df, transitions_df, repeat_df], axis=1)\n",
    "\n",
    "# Prepare features and labels\n",
    "X = result_df.drop(columns=['next_activity'])\n",
    "y = result_df['next_activity']\n",
    "\n",
    "# Handle rare classes\n",
    "rare_classes = y.value_counts()[y.value_counts() == 1].index.tolist()\n",
    "if len(rare_classes) == 1:\n",
    "    rare_class = rare_classes[0]\n",
    "    rare_class_rows = X[y == rare_class]\n",
    "    X = pd.concat([X, rare_class_rows], axis=0)\n",
    "    y = pd.concat([y, pd.Series([rare_class] * len(rare_class_rows))], axis=0)\n",
    "else:\n",
    "    new_label = max(y) + 1\n",
    "    y = y.replace(rare_classes, new_label)\n",
    "    others_rows = X[y.isin(rare_classes)]\n",
    "    X = pd.concat([X, others_rows], axis=0)\n",
    "    y = pd.concat([y, pd.Series([new_label] * len(others_rows))], axis=0)\n",
    "\n",
    "# Feature selection\n",
    "X_selected = SelectKBest(mutual_info_classif, k=20).fit_transform(X, y)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# GridSearchCV for best RandomForest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300], \n",
    "    'max_depth': [None, 10, 20, 30], \n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4], \n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "rf_model_selected = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf_model_selected, param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Cross-validation standard deviations\n",
    "cv_results = cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "accuracy_sd = np.std(cv_results)\n",
    "precision_sd = np.std(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='precision_weighted'))\n",
    "recall_sd = np.std(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='recall_weighted'))\n",
    "f1_sd = np.std(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='f1_weighted'))\n",
    "\n",
    "accuracy_cv = np.mean(cv_results)\n",
    "precision_cv = np.mean(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='precision_weighted'))\n",
    "recall_cv = np.mean(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='recall_weighted'))\n",
    "f1_cv = np.mean(cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='f1_weighted'))\n",
    "\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Accuracy (from GridSearch): {grid_search.best_score_:.4f}\")\n",
    "print(f\"Cross-Validated Accuracy: {accuracy_cv:.4f} (±{accuracy_sd:.4f})\")\n",
    "print(f\"Cross-Validated Precision: {precision_cv:.4f} (±{precision_sd:.4f})\")\n",
    "print(f\"Cross-Validated Recall: {recall_cv:.4f} (±{recall_sd:.4f})\")\n",
    "print(f\"Cross-Validated F1-Score: {f1_cv:.4f} (±{f1_sd:.4f})\")\n",
    "print(f\"\\nTest Set Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Set Precision: {precision:.4f}\")\n",
    "print(f\"Test Set Recall: {recall:.4f}\")\n",
    "print(f\"Test Set F1-Score: {f1:.4f}\")\n",
    "\n"
   ],
   "id": "3af4d7512c898ecc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
